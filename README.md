# Matrix-Matrix-Multiplication
https://youtu.be/9tz-KHTuZ_4?si=CT2wHK86FiFHxc0B
## Τοπολογία Δακτυλίου (Ring)
Ο κώδικας αποτελεί μια αποτελεσματική προσέγγιση στον παράλληλο πολλαπλασιασμό μητρώων εκμεταλλεύοντας τον παράλληλο χαρακτήρα του MPI (Message Passing Interface) για να επιτύχει αποδοτική κατανομή και επεξεργασία δεδομένων σε πολλαπλούς επεξεργαστές. Αρχικά, οι πίνακες δεδομένων κατανέμονται μεταξύ των διαθέσιμων διεργασιών, με την κάθε διεργασία να λαμβάνει ένα μέρος των δεδομένων για επεξεργασία. Αυτό επιτρέπει την κατανομή του φορτίου εργασίας και τη μείωση του χρόνου εκτέλεσης, καθώς πολλές διεργασίες επεξεργάζονται ταυτόχρονα διαφορετικά μέρη των δεδομένων. Για παράδειγμα, οι πίνακες B και C κατανέμονται σε υποπίνακες μεταξύ των διεργασιών, με κάθε διεργασία να επεξεργάζεται μόνο τον δικό της υποπίνακα, μειώνοντας έτσι την ανάγκη για σειριακή επεξεργασία και επιτρέποντας την ταυτόχρονη επεξεργασία πολλαπλών δεδομένων. Η τοπολογία δακτυλίου (ring topology) που χρησιμοποιείται σε αυτήν την υλοποίηση, εξασφαλίζει ότι οι διεργασίες είναι οργανωμένες με τέτοιο τρόπο ώστε να μπορούν να επικοινωνούν άμεσα με τις γειτονικές τους, επιτρέποντας τη συνεχή ροή δεδομένων γύρω από τον δακτύλιο. Η επικοινωνία γίνεται με τη χρήση της συνάρτησης `MPI_Cart_create` για τη δημιουργία της τοπολογίας και της `MPI_Cart_shift` για τον καθορισμό των διεργασιών προέλευσης και προορισμού. Αυτή η δομή διευκολύνει τη μετάδοση και λήψη δεδομένων με αποδοτικό τρόπο, μειώνοντας τον χρόνο που απαιτείται για την ανταλλαγή δεδομένων και αυξάνοντας την αποδοτικότητα της παράλληλης εκτέλεσης. Επιπλέον, η χρήση των συναρτήσεων `MPI_Scatter` και `MPI_Gather` για τη διασπορά και συλλογή δεδομένων, αντίστοιχα, επιτρέπει την ομοιόμορφη κατανομή και επανασύνθεση των δεδομένων, εξασφαλίζοντας ότι όλες οι διεργασίες συμμετέχουν ενεργά και αποδοτικά στην επεξεργασία.

### Διαμόρφωση Τοπολογίας
Δημιούργησα μια τοπολογία δακτυλίου για τις διαδικασίες υπολογισμού, ώστε να επικοινωνούν μεταξύ τους κατά τη διάρκεια της εργασίας τους, χρησιμοποιώντας το `MPI_Cart_create`, διαμορφώνοντας τις διεργασίες σε μια μονοδιάστατη κυκλική δομή. Δηλαδή, οι διεργασίες είναι διατεταγμένες σε κύκλο (σαν δαχτυλίδι), όπου κάθε διεργασία έχει έναν γείτονα στα αριστερά και έναν άλλο στα δεξιά. Η τοπολογία δακτυλίου επιλέγεται για την απλότητα και την αποτελεσματικότητά της στη διαδοχική μετάδοση δεδομένων που περνούν από τη μια διαδικασία στην άλλη. Αυτή η τοπολογία είναι ιδιαίτερα κατάλληλη για λειτουργίες όπου κάθε διεργασία χρειάζεται να επικοινωνεί με τον προκάτοχο και τον διάδοχο (γειτονικές διεργασίες) της με τρόπο που μοιάζει με αλυσίδα.

### Βελτιστοποίηση μνήμης
Χρησιμοποιώ αποτελεσματικά τη μνήμη και την βελτιστοποιώ μέσω προσεκτικής κατανομής και διαχείρισης των μητρώων. Υπάρχουν πολλές διεργασίες που λειτουργούν μαζί. Κάθε διεργασία εκχωρεί μνήμη μόνο για το τμήμα των πινάκων για το οποίο είναι υπεύθυνη, μειώνοντας το συνολικό αποτύπωμα μνήμης. Συγκεκριμένα, για τον πίνακα Β, κάθε διεργασία εκχωρεί μνήμη για ένα υπο-μητρώο (BPart) που αντιστοιχεί στις γραμμές που είναι υπεύθυνη για την επεξεργασία. Αυτή η τοπική κατανομή ελαχιστοποιεί τη χρήση μνήμης, επειδή κάθε διεργασία περιέχει μόνο ό,τι χρειάζεται και διασφαλίζει ότι οι διεργασίες δεν εκχωρούν μνήμη για δεδομένα που δεν χρειάζονται, οδηγώντας σε πιο αποτελεσματική χρήση των πόρων.

### Παράλλος Χαρακτήρας και Κατανομή Δεδομένων
Επιτυγχάνω παραλληλισμό μέσω του τεμαχισμού της εργασίας πολλαπλασιασμού μητρώων μεταξύ πολλαπλών διεργασιών.  Η ριζική διεργασία αρχικοποιεί τα μητρώα B και C και στη συνέχεια τεμαχίζει το μητρώο Β και διανέμει τμήματα του σε άλλες διεργασίες στον δακτύλιο χρησιμοποιώντας το `MPI_Scatter`. Κάθε διεργασία λαμβάνει ένα ξεχωριστό σύνολο γραμμών από το μητρώο Β για να εργαστεί και λειτουργεί ανεξάρτητα πάνω σε αυτό το σύνολο. Μετά από αυτό, το μητρώο C μεταδίδεται σε όλες τις διεργασίες χρησιμοποιώντας το `MPI_Bcast`, καθώς κάθε διεργασία απαιτεί το πλήρη μητρώο C για να εκτελέσει το μέρος του πολλαπλασιασμού του. Αυτό το σχήμα διανομής δεδομένων επιτρέπει σε όλες τις διεργασίες να λειτουργούν ταυτόχρονα σε διαφορετικά μέρη του υπολογισμού, ενισχύοντας την παράλληλη απόδοση.

### Απόδοση
Για την υλοποίηση του κώδικα έκανα τις εξής εκτιμήσεις απόδοσης:
#### Εξισορρόπηση Φόρτου Εργασίας
Εξασφαλίζει ομοιόμορφη κατανομή του φόρτου εργασίας μεταξύ των διαδικασιών τεμαχίζοντας το μητρώο Β σε ίσα μέρη. Αυτή η εξισορρόπηση φορτίου είναι ζωτικής σημασίας για την επίτευξη βέλτιστης παράλληλης απόδοσης, καθώς αποτρέπει ορισμένες διεργασίες από το να είναι αδρανείς ενώ άλλες εξακολουθούν να λειτουργούν.
#### Επιβάρυνση Επικοινωνίας
Η τοπολογία δακτυλίου έχει σχεδιαστεί για να ελαχιστοποιεί την επιβάρυνση της επικοινωνίας. Με την οργάνωση διεργασιών σε έναν δακτύλιο, κάθε διεργασία επικοινωνεί μόνο με δύο γείτονες (εκτός από τη ριζική διεργασία κατά τη διάρκεια των λειτουργιών scatter και gather), μειώνοντας την πολυπλοκότητα και την καθυστέρηση της ανταλλαγής δεδομένων.
#### Υπολογισμός - Επικοινωνία 
Στοχεύει στη μεγιστοποίηση του λόγου υπολογισμού προς επικοινωνία. Με την αποτελεσματική μετάδοση του μητρώου C και της διασκόρπισης του μητρώου Β, το πρόγραμμα μειώνει τη συχνότητα και τον όγκο της επικοινωνίας μεταξύ των διεργασιών, επιτρέποντας περισσότερο χρόνο για τον πραγματικό υπολογισμό.
#### Μοτίβα Πρόσβασης στη μνήμη 
Έχει σχεδιαστεί έχοντας κατά νου αποτελεσματικά μοτίβα πρόσβασης στη μνήμη, ιδιαίτερα στον τρόπο αποθήκευσης και πρόσβασης των μητρώων κατά τη διάρκεια του πολλαπλασιασμού. Αυτό διασφαλίζει ότι η χρήση της προσωρινής μνήμης είναι βελτιστοποιημένη, βελτιώνοντας περαιτέρω την απόδοση.

## Τοπολογία Πλέγματος (Grid) 
Ο δεύτερος κώδικας παράλληλου υπολογισμού βασίζεται και αυτός στο MPI, και εκτελεί με αποτελεσματικό τρόπο τον πολλαπλασιασμό πινάκων σε πολλαπλές διεργασίες, χρησιμοποιώντας την τοπολογία καρτεσιανού πλέγματος 2D, βελτιστοποιημένη διαχείριση μνήμης καθώς και τεχνικές παράλληλου υπολογισμού. Ο παράλληλος χαρακτήρας αυτής της υλοποίησης αναδεικνύεται από την κατανομή των εργασιών μεταξύ πολλών διεργασιών. Αρχικά, γίνεται αρχικοποίηση του MPI και κάθε διεργασία λαμβάνει ένα αναγνωριστικό (rank) και ο συνολικός αριθμός των διεργασιών ανακτάται. Οι διεργασίες οργανώνονται σε πλέγμα και κάθε διεργασία αναλαμβάνει συγκεκριμένες γραμμές και στήλες των πινάκων για υπολογισμούς. Η ριζική διεργασία αρχικοποιεί τους πίνακες B και C με τιμές που παρέχονται από τον χρήστη και τους μεταδίδει σε όλες τις άλλες διεργασίες. Κάθε διεργασία υπολογίζει ένα τμήμα του προκύπτοντος πίνακα A βάσει του ανατεθέντος υποπλέγματος. Η ριζική διεργασία συλλέγει αυτά τα τμήματα, συναρμολογεί τον πλήρη πίνακα A και τον γράφει σε αρχείο εξόδου. Η χρήση των συναρτήσεων MPI όπως MPI_Init, MPI_Comm_rank, MPI_Comm_size, MPI_Bcast και MPI_Send/MPI_Recv διευκολύνει τους αποδοτικούς παράλληλους υπολογισμούς και την επικοινωνία μεταξύ διεργασιών, επιδεικνύοντας τη δύναμη του παραλληλισμού στη διαχείριση μεγάλης κλίμακας πράξεων με πίνακες.

### Διαμόρφωση Τοπολογίας
Το πρόγραμμα αρχικοποιεί μια τοπολογία καρτεσιανού πλέγματος 2D για την πιο αποτελεσματική διαχείριση της επικοινωνίας των διεργασιών και της διανομής δεδομένων. Η επιλογή ενός πλέγματος 2D έναντι μιας διάταξης 1D βελτιώνει την τοποθεσία των δεδομένων και μειώνει την επιβάρυνση της επικοινωνίας για ορισμένες λειτουργίες. Οι διαστάσεις αυτού του πλέγματος καθορίζονται δυναμικά με βάση το συνολικό αριθμό των διεργασιών και βελτιστοποιούνται με τέτοιο τρόπο ώστε να διασφαλίζεται ότι το πλέγμα έχει τη μικρότερη δυνατή διαφορά μεταξύ του αριθμού των γραμμών και των στηλών, γεγονός που ευνοεί την πιο ισορροπημένη κατανομή του φόρτου εργασίας και την αποτελεσματικότερη επικοινωνία μεταξύ των διεργασιών.

### Βελτιστοποίηση Μνήμης
Η βελτιστοποίηση της μνήμης επιτυγχάνεται μέσω της συνετής κατανομής της μνήμης και του σχεδιασμού δομών δεδομένων. Οι πίνακες αποθηκεύονται σε συνεχόμενα μπλοκ μνήμης, με σκοπό να βελτιωθεί η ταχύτητα πρόσβασης στα δεδομένα και να μειωθεί ο κατακερματισμός. Οι δείκτες σε αυτά τα μπλοκ διευκολύνουν τον πιο αποτελεσματικό χειρισμό των δεδομένων, χωρίς περιττή αντιγραφή ή μετακίνηση δεδομένων, ελαχιστοποιώντας την επιβάρυνση κατά το χρόνο εκτέλεσης. Κάθε διεργασία κατανέμει μνήμη μόνο για το δικό της τμήμα των δεδομένων, ιδίως για τον πίνακα που προκύπτει, μειώνοντας έτσι σημαντικά το αποτύπωμα της μνήμης σε κάθε κόμβο και εξασφαλίζοντας επεκτασιμότητα.

### Παράλληλος Χαρακτήρας και Διανομή Δεδομένων
Ο υπολογισμός του πίνακα που προκύπτει, δηλαδή του πίνακα A, κατανέμεται μεταξύ των διαθέσιμων διεργασιών. Κάθε μία διεργασία είναι υπεύθυνη για τον υπολογισμό ενός υποπλέγματος του πίνακα A που αντιστοιχεί στο τμήμα των πινάκων B και C που λαμβάνει. Αυτός ο καταμερισμός εργασίας εξασφαλίζει ότι ο φόρτος της εργασίας κατανέμεται ομοιόμορφα, μεγιστοποιώντας με αυτό τον τρόπο τη χρήση των διαθέσιμων υπολογιστικών πόρων. Επίσης, το πρόγραμμα μεταδίδει τους πίνακες B και C σε όλες τις διεργασίες, εξασφαλίζοντας ότι κάθε μία από αυτές διαθέτει τα απαραίτητα δεδομένα για να εκτελέσει τους υπολογισμούς της. Η προσέγγιση αυτή επιλέγεται για την απλότητα και την αποτελεσματικότητά της, δεδομένης της φύσης του πολλαπλασιασμού πινάκων, όπου κάθε στοιχείο του πίνακα που προκύπτει είναι ανεξάρτητο από τα υπόλοιπα. Μετά τον υπολογισμό, η διεργασία της ρίζας συγκεντρώνει τα υποπλέγματα και τα συναρμολογεί στον τελικό πίνακα A. Αυτό το βήμα υπόκειται σε προσεκτική διαχείριση, για να διασφαλιστεί ότι τα δεδομένα από κάθε διεργασία τοποθετούνται σωστά στον πίνακα που προκύπτει, διατηρώντας την ακεραιότητα του τελικού υπολογισμού.

### Απόδοση
Η υλοποίηση του κώδικα βελτιώνει την απόδοση, πετυχαίνοντας:
#### Βέλτιστη Επικοινωνία 
Χρησιμοποιεί καρτεσιανό πλέγμα και συναρτήσεις MPI για καλύτερη επικοινωνία, μειώνοντας την καθυστέρηση και τη χρήση εύρους ζώνης.
#### Βελτιστοποίηση Μνήμης 
Βελτιστοποιεί τη μνήμη, μειώνοντας τις συνολικές απαιτήσεις και ενισχύοντας την αποδοτικότητα της κρυφής μνήμης.
#### Εξισορρόπηση Φόρτου Εργασίας 
Εξασφαλίζει ισορροπημένο φόρτο εργασίας σε όλους τους επεξεργαστές, μειώνοντας τον χρόνο αδράνειας και επιτυγχάνοντας σημαντική επιτάχυνση σε σχέση με τη σειριακή εκτέλεση.
